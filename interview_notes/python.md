## Интерпретатор Python

Python является **интерпретируемым** языком.
При запуске скрипта на Python код **компилируется в байткод** (.pyc файлы),
а далее **байткод выполняется на виртуальной машине (ВМ)**.

Байт-код обеспечивает **кроссплатформенность**, его выполнением занимается часть интерпретатора,
называющаяся **виртуальной машиной**.

---

### GIL (Global Interpreter Lock)
***GIL*** – это **мьютекс**, защищающий внутренние объекты интерпретатора от 
некорректного взаимодействия с несколькими потоками.

Главным образом GIL обеспечивает **безопасную работу сборщика мусора** (механизм подсчета ссылок).

---

### GC - Garbage Collector (сборщик мусора)
Каждый объект интерпретатора **_CPython_** имеет **атрибут** `ref_count` – **счетчик ссылок**. 
Когда он становится равным 0, объект сразу **деаллоцируется**.

При этом **оператор** `del` не удаляет объект, а **декрементирует счетчик ссылок**.

Сборщик мусора работает с **тремя поколениями объектов**. 
**Изначально объект принадлежит первому поколению**, 
далее если он пережил сборку мусора, переходит в следующее поколение.

**Порог перехода в следующее поколение это количество сборок мусора**, его можно переопределить
с помощью метода `gc.set_threshold` пакета `gc`.

Чем выше поколение, тем реже оно сканируется сборщиком мусора.

---

## Генераторы

Генератор – подвид итератора, хранящий закономерность вычисления последовательности.
Генераторы **хранят в памяти только текущий элемент последовательности**.

Генератор генерирует значения, возвращающиеся по запросу, 
и после возврата одного значения выполнение функции-генератора приостанавливается до запроса следующего значения. 
Между вызовами **генератор сохраняет свое состояние, помнит о контексте** в отличие от функций с оператором `return`.

Генераторы можно создать **двумя способами**:
1. **генераторное выражение**;
2. **функция-генератор** с оператором `yield`.

**Генераторы поддерживают 3 метода**:
1. `close` - **закрытие** генератора;
2. `send` - генератор может **принять значение** после (`value = yield`);
3. `throw` - возбудить **исключение** (`gen.throw(AnyError)`).

**Пример**:
```python
# generator expression
genexpr = (x**2 for x in range(1, 5))

next(genexpr)
>> 1
next(genexpr)
>> 4
next(genexpr)
>> 9

# generator
def batch_read(lines):
    buff = []
    batch_count = None

    for line in lines:
        if batch_count is None:
            batch_count = yield

        buff.append(line)

        if len(buff) == batch_count:
            # такой синтаксис юзается для одновременного принятия значения из метода send и возврата значения
            batch_count = yield buff  
            buff.clear()

    if buff:
        yield buff

# подобным образом можно было бы вычитать файл любого размера
lines = ['1', '', '3', '4', '5', '', '7', '8', '']
gen = batch_read(lines)
# Иницализация генератора, причем next(gen) это то же самое, что и gen.send(None)
next(gen)

print(gen.send(2))
print(gen.send(1))
print(gen.send(1))
print(gen.send(4))
>> ['1', '']
>> ['3']
>> ['4']
>> ['5', '', '7', '8']

```

---

## Итерируемый объект, итератор

**Итерируемый объект (`Iterable`)** - объект, предоставляющий логику перебора последовательности.
Реализует метод `__iter__` или `__getitem__`.

**Итератор (`Iterator`)** - итерируемый объект, умеющий запоминать свое состояние. Для этого он реализует метод `__next__`.

**Отличие** `Iterable` от `Iterator`: **итератор** - это **подвид** `Iterable`, **исчерпывающийся** при полном переборе.

**Примеры**:
* **список** - это **Iterable**, но **не Iterator** (_список перебирается, но не может быть исчерпан_);
* **генератор** относится и к **Iterable** и к **Iterator** (_генератор перебирается и исчерпывается_).

**Как работает цикл** `for`: 
1. цикл пытается взять итератор от объекта (`iter(obj)`);
2. на каждой итерации цикл вызывает у объекта метод `__next__` до возникновения исключение `StopIteration`.

---

## Хеш-таблицы (словари)

**Хеш-таблица** или **словарь** выглядит как **одномерный массив**, каждый элемент которого называется **бакетом**.

**Алгоритм добавления элемента**:
1. для ключа **вычисляется хеш** с помощью встроенной функции `hash`;
2. хеш используется для определения индекса бакета: 
`bucket_idx = hash_value % len(arr)`, где `arr` – **массив бакетов**;

3. в бакет записывается **пара ключ-значение**.

**Получение элемента по ключу**: для ключа **вычисляется хеш**, **определяется бакет**
и из него берется пара ключ-значение.

**Алгоритмическая сложность получения элемента** в хеш-мапе **константная** – `O(1)` 
(равняется времени работы алгоритма хеширования).

**Коллизии**: ситуация, при которой алгоритм хеширования выдает для разных ключей одинаковые значения, 
называется коллизией. 

**Коллизии можно резолвить** несколькими способами. 
Например, **методом цепочек**, в котором вместо значения в бакет кладется **связный список** значений. 
При этом, **алгоритмическая сложность** получения элемента становится **линейной**, 
потому что придется пробежаться по всем элементам связного списка, чтобы найти искомый элемент.

Хеш-таблицы занимают много памяти, т.к. необходимо выделять память под количество бакетов примерно равное количеству элементов.

**Ключами словаря** в Python **могут являться только хешируемые объекты** - 
объекты с реализацией методов `__hash__` и `__eq__` (_второй метод может использоваться для резолва коллизий_).

---

## Асинхронность и asyncio

**Корутина** – результат вызова асинхронной функции. Главное свойство - **запоминание контекста**
(подобно генератору).

**Сокет** – абстракция сетевого взаимодействия ОС (**представляет из себя особый файл**).
Сокет поддерживает операции **чтения и записи**.
С точки зрения сетевого взаимодействия сокет - это **хост + порт**.

asyncio следует модели **кооперативной многозадачности**, когда вместо ОС мы сами определяем
точки переключения контекста с помощью оператора `await`, а весь конкурентный рантайм
выполняется в **одном потоке**.

### Принципы работы и внутреннего устройства asyncio
Корутины сами по себе **не предоставляют возможности конкурентного выполнения**, 
но конкуретность возможна благодаря **задачам**. 

**Задача** - **обертка** над корутиной, которая управляется **циклом событий**.

asyncio использует низкоуровневое API пакетов `select`/`selectors`, которые
по сути обертывают вызовы в ядро операционной системы.

По сути, любую **задачу** можно проассоциировать с **сокетом**, а далее опрашивать ОС
на предмет доступных для взаимодействия сокетов с помощью вышеупомянутого API.

Когда сокет станет доступным, ОС выполнит заданный **коллбэк**. 
Коллбэк можно повесить как на операцию чтения, так и записи.

asyncio опрашивает ОС знает состояние сокета (можем ли мы делать операции *read*/*write* в сокете). 
Если сокет недоступен, контекст переключается (подобно `yield` в генераторе) 
и **выполняются следующие задачи из очереди цикла событий**.

---

## Чистая функция

**Чистая функция** – функция, удовлетворяющая следующим **критериям**:
1. **всегда возвращает одно** и то же **значение** **для одних и тех же** значений **входных** **параметров**;
2. **не имеет побочных эффектов** (не влияет на код, содержащийся вне функции. Например, не меняет значения глобальных переменных, не использует потоки ввода-вывода).

**Преимущества**:
* предсказуемость;
* легкая тестируемость.

---

## MRO (порядок разрешения методов)

*MRO* представляет из себя **алгоритм линеаризации иерархии класса для разрешения конфликтных ситуаций при множественном наследовании**.

В старых версиях *Python* реализация *MRO* напоминала **обход** бинарного дерева **в глубину**, 
но это порождало множество проблем, т.к. в глубину можно было дойти до класса `object`
(могли вызываться бы одноименные методы класса `object`). Теперь *MRO* работает подобно **обходу в ширину**.

Чтобы увидеть линейный вид иерархии и понять приоритетность каждой сущности в иерархии наследования, 
можно распечатать результат вызова **у класса** метода `mro` или магического атрибута `__mro__` у объекта.

---

## Метаклассы
**Все сущности** в языке *Python* **являются** **объектами**, включая классы.
**Метакласс – это сущность, объекты которой являются классами**.

Для определения типа класса можно вызвать метод `type` и увидеть, что метод возвращает `<class 'type'>`. 
То есть, любой объект в Python имеет тип `type`.

`type` является метаклассом и может работать в двух режимах, в первом из которых `type` принимает 
1 аргумент – тип объекта, и возвращает его базовый тип, а во втором принимает **3 аргумента**:
* ***name*** - название класса;
* ***base*** - кортеж родительских классов (может быть пустым);
* ***attrs*** - словарь, содержащий имена и значения атрибутов.

Используя `type` во втором режиме, можно **динамически** **создавать классы** с атрибутами.

Также можно создать свой метакласс, наследуясь от `type`, и в определении целевого класса указать `metaclass=<имя метакласса>`.

---

## SOLID

***SOLID*** это совокупность 5 базовых принципов проектирования объектно-ориентированных систем.

***S (Single Responsibility)*** – **принцип единственной ответственности**, 
согласно которому сущность должна выполнять только одну задачу (у сущности должна быть только одна причина для изменения);

***O (Open-Closed Principle)*** – **принцип открытости-закрытости**. 
Добавление и модификация функционала не должны приводить к изменениям существующего;

***L (Liskov Substitution Principle)*** – **принцип подстановки Лисков**. 
Классы-наследники не должны противоречить базовому классу;

**Пример**: **наследование класса *Square* от *Rectangle* является нарушением** данного принципа, 
т.к. эти сущности ведут себя по-разному:

```python
# сущность типа Rectangle пройдет данный тест, 
#  но Square как наследник Rectangle – нет, т.к. у квадрата все стороны равны

def test_shape_area(figure: Rectangle):
    figure.width = 10
    figure.height = 20

    assert figure.get_area() == 200
```

Тест выше можно сделать корректным, **усложнив** его логику проверками типов:
```python
if is_instance(figure, Rectangle) ...

if is_instance(figure, Square) ...
```

Но подобные **усложнения** показывают, что мы делаем что-то не так.
Полиморфизм и наследование придуманы для обобщения, а не для лишних проверок на типы, 
в зависимости от которых выполнялась бы разная логика.

***I (Interface Segregation Principle)*** – **принцип разделения интерфейсов**. 
Лучше создавать много мелких узкоспециализированных интерфейсов, чем большие, 
часть функционала которых будет не нужна некоторым классам.

***D (Dependency Inversion Principle)*** – **принцип инверсии зависимостей**. 
Метод/функция должна зависеть от абстракции, а внедряемая зависимость должна реализовывать интерфейс абстракции:
```python
# функция зависит от абстракции
def do_smth(dep: Abstraction): ...
# конкретная реализация соответсвует интерфейсу абстракции
class ConcreteEntity(Abstraction): ...

dep = ConcreteEntity()
do_smth(dep=dep)
```

Также можно понимать **инверсию** с точки зрения **потоков управления** и **зависимостей**:
* **поток управления** - `api layer -> service layer -> ...`
* **поток зависимостей** - `api layer <- service layer <- domain`


**Пример**: <https://solidbook.vercel.app/dip/in-ideal-world>.

Также в контексте *SOLID* часто употребляются следующие **два термина**:

1. [**Зацепление**](https://ru.wikipedia.org/wiki/%D0%97%D0%B0%D1%86%D0%B5%D0%BF%D0%BB%D0%B5%D0%BD%D0%B8%D0%B5_%28%D0%BF%D1%80%D0%BE%D0%B3%D1%80%D0%B0%D0%BC%D0%BC%D0%B8%D1%80%D0%BE%D0%B2%D0%B0%D0%BD%D0%B8%D0%B5%29) - **степень зависимости** разных модулей друг от друга. Чем выше зацепление, тем хуже;
2. [**Связность**](https://ru.wikipedia.org/wiki/%D0%A1%D0%B2%D1%8F%D0%B7%D0%BD%D0%BE%D1%81%D1%82%D1%8C_%28%D0%BF%D1%80%D0%BE%D0%B3%D1%80%D0%B0%D0%BC%D0%BC%D0%B8%D1%80%D0%BE%D0%B2%D0%B0%D0%BD%D0%B8%D0%B5%29) - степень следования принципу _SRP_.

---
